{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning in Julia with MLJ\n",
    "\n",
    "Welcome to this little Jupyter Notebook for getting to know MLJ, the goto ML platform within Julia.\n",
    "\n",
    "To start with, take a look at [MLJ's github page](https://github.com/alan-turing-institute/MLJ.jl):\n",
    "* super well organized: own [Github Organization \"JuliaAI\"](https://github.com/JuliaAI)\n",
    "* well maintained and supported: see the maintainers and support below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> -----------------------------\n",
    ">\n",
    "> <div align=\"center\">\n",
    ">     <img src=\"https://github.com/alan-turing-institute/MLJ.jl/raw/dev/material/MLJLogo2.svg\" alt=\"MLJ\" width=\"200\">\n",
    "> </div>\n",
    "> \n",
    "> <h2 align=\"center\">A Machine Learning Framework for Julia\n",
    "> </h2>\n",
    "> \n",
    "> \n",
    "> MLJ (Machine Learning in Julia) is a toolbox written in Julia\n",
    "> providing a common interface and meta-algorithms for selecting,\n",
    "> tuning, evaluating, composing and comparing over [160 machine learning\n",
    "> models](https://alan-turing-institute.github.io/MLJ.jl/dev/list_of_supported_models/)\n",
    "> written in Julia and other languages.\n",
    "> \n",
    "> **New to MLJ?** Start [here](https://alan-turing-institute.github.io/MLJ.jl/dev/).\n",
    "> \n",
    "> **Integrating an existing machine learning model into the MLJ\n",
    "> framework?** Start [here](https://alan-turing-institute.github.io/MLJ.jl/dev/quick_start_guide_to_adding_models/).\n",
    "> \n",
    "> MLJ was initially created as a Tools, Practices and Systems project at\n",
    "> the [Alan Turing Institute](https://www.turing.ac.uk/)\n",
    "> in 2019. Current funding is provided by a [New Zealand Strategic\n",
    "> Science Investment\n",
    "> Fund](https://www.mbie.govt.nz/science-and-technology/science-and-innovation/funding-information-and-opportunities/investment-funds/strategic-science-investment-fund/ssif-funded-programmes/university-of-auckland/)\n",
    "> awarded to the University of Auckland.\n",
    "> \n",
    "> MLJ been developed with the support of the following organizations:\n",
    "> \n",
    "> <div align=\"center\">\n",
    ">     <img src=\"https://github.com/alan-turing-institute/MLJ.jl/raw/dev/material/Turing_logo.png\" width = 100/>\n",
    ">     <img src=\"https://github.com/alan-turing-institute/MLJ.jl/raw/dev/material/UoA_logo.png\" width = 100/>\n",
    ">     <img src=\"https://github.com/alan-turing-institute/MLJ.jl/raw/dev/material/IQVIA_logo.png\" width = 100/>\n",
    ">     <img src=\"https://github.com/alan-turing-institute/MLJ.jl/raw/dev/material/warwick.png\" width = 100/>\n",
    ">     <img src=\"https://github.com/alan-turing-institute/MLJ.jl/raw/dev/material/julia.png\" width = 100/>\n",
    "> </div>\n",
    "> \n",
    "> \n",
    "> ### The MLJ Universe\n",
    "> \n",
    "> The functionality of MLJ is distributed over a number of repositories\n",
    "> illustrated in the dependency chart below. These repositories live at\n",
    "> the [JuliaAI](https://github.com/JuliaAI) umbrella organization.\n",
    "> \n",
    "> <div align=\"center\">\n",
    ">     <img src=\"https://github.com/alan-turing-institute/MLJ.jl/raw/dev/material/MLJ_stack.svg\" alt=\"Dependency Chart\">\n",
    "> </div>\n",
    "> \n",
    "> *Dependency chart for MLJ repositories. Repositories with dashed\n",
    "> connections do not currently exist but are planned/proposed.*\n",
    "> \n",
    "> <br>\n",
    "> <p align=\"center\">\n",
    "> <a href=\"CONTRIBUTING.md\">Contributing</a> &nbsp;•&nbsp; \n",
    "> <a href=\"ORGANIZATION.md\">Code Organization</a> &nbsp;•&nbsp;\n",
    "> <a href=\"ROADMAP.md\">Road Map</a> \n",
    "> </br>\n",
    "> \n",
    "> #### Contributors\n",
    "> \n",
    "> *Core design*: A. Blaom, F. Kiraly, S. Vollmer\n",
    "> \n",
    "> *Lead contributor*: A. Blaom\n",
    "> \n",
    "> *Active maintainers*: A. Blaom, S. Okon, T. Lienart, D. Aluthge\n",
    "> \n",
    ">\n",
    "> ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: Many examples and text snippets are taken directly from documentation and examples provided by MLJ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's jump into it: Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@iload DecisionTreeClassifier  # interactive model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load DecisionTreeClassifier pkg=DecisionTree  # declaritive model loading\n",
    "tree = DecisionTreeClassifier()  # instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLJ is essentially a big wrapper providing unified access to other packages containing the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RDatasets\n",
    "iris = RDatasets.dataset(\"datasets\", \"iris\"); # a DataFrame\n",
    "y, X = unpack(iris, ==(:Species), colname -> true); # y = a vector, and X = a DataFrame \n",
    "first(X, 3) |> pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "### Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(tree, X, y)  # adding a mutable cache to the model+data for performant training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=false); # 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit!(mach, rows=train)\n",
    "yhat = predict(mach, X[test,:]);\n",
    "yhat[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "isa(yhat[1], Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributions.mode.(yhat[3:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(yhat, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in measures()\n",
    "    if \"log_loss\" in m.instances\n",
    "        display(m)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate = auto fit/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(tree, X, y)  # adding a mutable cache to the model for performant training \n",
    "evaluate!(mach, resampling=Holdout(fraction_train=0.7, shuffle=false),\n",
    "    measures=[log_loss, brier_score], verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.max_depth = 3\n",
    "evaluate!(mach, resampling=CV(shuffle=true), measure=[accuracy, balanced_accuracy], operation=predict_mode, verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning: fit!, transform, inverse_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [1, 2, 3, 4]\n",
    "mach2 = machine(UnivariateStandardizer(), v)\n",
    "fit!(mach2)\n",
    "w = transform(mach2, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform(mach2, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry\n",
    "\n",
    "MLJ has a model registry, allowing the user to search models and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models(matching(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(\"DecisionTreeClassifier\", pkg=\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLJ features\n",
    "\n",
    "\n",
    "MLJ (Machine Learning in Julia) is a toolbox written in Julia\n",
    "providing a common interface and meta-algorithms for selecting,\n",
    "tuning, evaluating, composing and comparing machine learning models\n",
    "written in Julia and other languages. In particular MLJ wraps a large\n",
    "number of [scikit-learn](https://scikit-learn.org/stable/) models. \n",
    "\n",
    "\n",
    "* Data agnostic, train models on any data supported by the\n",
    "  [Tables.jl](https://github.com/JuliaData/Tables.jl) interface,\n",
    "\n",
    "* Extensive support for model composition (*pipelines* and *learning\n",
    "  networks*),\n",
    "\n",
    "* Convenient syntax to tune and evaluate (composite) models.\n",
    "\n",
    "* Consistent interface to handle probabilistic predictions.\n",
    "\n",
    "* Extensible [tuning\n",
    "  interface](https://github.com/alan-turing-institute/MLJTuning.jl),\n",
    "  to support growing number of optimization strategies, and designed\n",
    "  to play well with model composition.\n",
    "\n",
    "\n",
    "More information is available from the [MLJ design paper](https://github.com/alan-turing-institute/MLJ.jl/blob/master/paper/paper.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model composition\n",
    "\n",
    "MLJ supports extremely flexible and multi-purpose model composition. It is described in detail in [the documentation](https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/) or a [respective paper](https://arxiv.org/abs/2012.15505).\n",
    "\n",
    "These compositions are called \"learning networks\" by MLJ, and the best place to start with them is a [learning-networks-tutorial by MLJ](https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/learning-networks/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO explore the learning-networks-tutorial and see that it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for being here\n",
    "\n",
    "further information:\n",
    "* MLJ repository: https://github.com/alan-turing-institute/MLJ.jl\n",
    "* MLJ docs: https://alan-turing-institute.github.io/MLJ.jl/dev/\n",
    "* MLJ tutorials: https://alan-turing-institute.github.io/DataScienceTutorials.jl/\n",
    "\n",
    "In case you have more questions or suggestions, always feel welcome to reach out to me at Meetup and Julia User Group Munich, or directly at Stephan.Sahm@gmx.de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
