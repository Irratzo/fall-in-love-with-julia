{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jolin-io/fall-in-love-with-julia/main?filepath=12%20concurrent%20programming%20-%2001%20introduction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.jolin.io\" target=\"_blank\" rel=\"noreferrer noopener\">\n",
    "<img src=\"https://www.jolin.io/assets/Jolin/Jolin-Banner-Website-v1.1-darkmode.webp\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall-in-love-with-Julia: Concurrent Programming in Julia 101\n",
    "\n",
    "an introduction session\n",
    "\n",
    "I am Stephan Sahm, and today we are going to learn all about meta.\n",
    "\n",
    "1. Asyncronous programming 🚲\n",
    "2. Multi-threading 🚘\n",
    "3. Parallel computing 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asyncronous programming 🚲\n",
    "\n",
    "Compute concurrently on the same thread.\n",
    "\n",
    "`@async`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function countdown(from=10)\n",
    "    @async begin\n",
    "        for i in from:-1:0\n",
    "            println(\"countdown $(i)\")\n",
    "            sleep(1)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sleep_blocking(seconds)\n",
    "    now = Dates.now()\n",
    "    until = now + Dates.Second(seconds)\n",
    "\n",
    "    while now < until\n",
    "        now = Dates.now()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown(5)\n",
    "sleep_blocking(3)\n",
    "println(\"awake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown(5)\n",
    "sleep(3)\n",
    "println(\"awake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### your space 😎\n",
    "\n",
    "👉 Print the current time in addition to the countdown value to see that execution is really stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 What would happen if we used `sleep_blocking` in the async task? Try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes Julia is running a scheduler which takes care of switching between tasks.\n",
    "\n",
    "> 🪧 Now you understand, why `sleep` may actually sleep much longer than you specified. `sleep` returns control to the scheduler and if another task becomes active inbetween, there is no other way, but to wait until the scheduler regains control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `wait` and `fetch`\n",
    "\n",
    "beside `sleep` there are other ways to organise green threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = countdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(task)\n",
    "println(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = countdown()\n",
    "result = fetch(task)\n",
    "@show result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### your space 🤓\n",
    "\n",
    "👉 Change the return value of your asyncronous countdown task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `@sync`\n",
    "if you directly want to wait on multiple `@async` calls, you can use `@sync`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function countdown_blocking(id, from=10)\n",
    "    println(\"begin countdown $id\")\n",
    "    wait(countdown(from))\n",
    "    println(\"end countdown $id\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync begin\n",
    "    @async countdown_blocking(\"from 4\", 4)\n",
    "    \n",
    "    @async countdown_blocking(\"from 6\", 6)\n",
    "    \n",
    "    @async countdown_blocking(\"from 2\", 2)\n",
    "end\n",
    "println(\"all done\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `notify` & `Condition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = Condition()  # think of this as a trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@async begin\n",
    "    # this will block until we trigger the Condition\n",
    "    wait(cond)\n",
    "    println(\"triggered $(Dates.now())\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notify(cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 🪧 Condition == rerunning the `wait` will wait again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `notify` & `Event`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = Base.Event()  # think of this as a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@async begin\n",
    "    # this will block until the Event is set to \"on\"\n",
    "    wait(event)\n",
    "    println(\"triggered $(Dates.now())\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notify(event)  # set state to \"on\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 🪧 Event == rerunning the `wait` will succeed immediately (until Event is reset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset(event)  # set state to \"off\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Channel` & `take!` & `put!`\n",
    "\n",
    "A `Channel` is *the* mean of communication between concurrent code (holds true for all kinds of concurrent programming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_countdown_channel(from=10)\n",
    "    Channel(4) do ch\n",
    "        for i in from:-1:0\n",
    "            sleep(1)\n",
    "            put!(ch, i)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_countdown = create_countdown_channel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while isopen(channel_countdown)\n",
    "    i = take!(channel_countdown)\n",
    "    println(\"countdown $i\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in channel_countdown\n",
    "    println(\"countdown $i\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 🪧 Channel() will pass only a single message at a time. `put!` \n",
    "\n",
    "> 🪧 Channel(4) will buffer 4 elements in the channel itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### your space 😎\n",
    "\n",
    "👉 Change the number of buffered elements. What do you think will change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 Exchange the `sleep` and `put!`. Can you guess what will change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-threading 🚘\n",
    "\n",
    "Use `Threads.@spawn` instead of `@async`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ be careful to write threadsafe code ⚠️\n",
    "\n",
    "> Warning from Julia documentation: \"Multi-threaded programming has many inherent difficulties, and if a program using threads exhibits unusual or undesirable behavior (e.g. crashes or mysterious results), thread interactions should typically be suspected first.\"\n",
    "\n",
    "👉 Why is multi-threading more dangerous than asynchronous programming?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is not possible in Julia to add threads within a running Julia process. \n",
    "# It needs to be done on the command line.\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.threadid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function threads_countdown(from=10)\n",
    "    Threads.@spawn begin\n",
    "        Core.println(Threads.threadid())\n",
    "        for i in from:-1:0\n",
    "            Core.println(\"countdown $(i) $(Dates.now())\")\n",
    "            sleep_blocking(1)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(Dates.now())\n",
    "threads_countdown(5)\n",
    "sleep_blocking(3)\n",
    "println(\"awake $(Dates.now())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wait`, `fetch`, `@sync` work all out of the box for threads as well, which is nice, but..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAUTION\n",
    "\n",
    "There is a known [issue](https://github.com/JuliaLang/julia/issues/43952) with `Threads.@spawn`\n",
    "\n",
    "- using standard `println` will break the independence\n",
    "- using `sleep(1)` instead of `sleep_blocking(1)` will also break it\n",
    "\n",
    "Here [another issue](https://github.com/JuliaLang/julia/issues/41586#issuecomment-880875258) which describes further difficulties. And [another](https://github.com/JuliaLang/julia/issues/34267).\n",
    "\n",
    "The support for threads will improve over the next Julia versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For what should you use Threads then?\n",
    "\n",
    "Speed up by \"simple\" parallelization of independent tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- package [`ThreadPools`](https://github.com/tro3/ThreadPools.jl), and the similar but already builtin `Threads.@threads`\n",
    "- package [`ThreadsX`](https://github.com/tkf/ThreadsX.jl) gives threaded versions of many builtin functions like `any`, `sum`, etc.\n",
    "- package [`Transducers`](https://juliafolds.github.io/Transducers.jl/dev/parallelism/#overview-parallel) is all about stream transformations and also supports threaded parallization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another warning: Atomic operations example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Ref(0)\n",
    "\n",
    "Threads.@threads for i in 1:1000\n",
    "    acc[] += 1\n",
    "end\n",
    "\n",
    "acc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Threads.Atomic{Int64}(0)\n",
    "\n",
    "Threads.@threads for i in 1:1000\n",
    "      Threads.atomic_add!(acc, 1)\n",
    "end\n",
    "\n",
    "acc[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you really want to use more low-level threads\n",
    "\n",
    "1. Read about **locks** in the [documentation](https://docs.julialang.org/en/v1/manual/multi-threading/#Data-race-freedom) and api, e.g. [ReentrantLock](https://docs.julialang.org/en/v1/base/parallel/#Base.ReentrantLock), [Semaphore](https://docs.julialang.org/en/v1/base/parallel/#Base.Semaphore), and [SpinLock](https://docs.julialang.org/en/v1/base/multi-threading/#Low-level-synchronization-primitives)\n",
    "\n",
    "2. Read about **atomic operations** in the [documentation](https://docs.julialang.org/en/v1/manual/multi-threading/#man-atomics) and [api](https://docs.julialang.org/en/v1/base/multi-threading/#Base.@atomic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computing 🚀\n",
    "\n",
    "doing things completely independently on multiple worker processes\n",
    "\n",
    "while the main process is usually orchestrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed  # standard library which comes with every julia distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.addprocs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.nprocs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RemoteChannel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `@everywhere`\n",
    "\n",
    "run code on all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.@everywhere using InteractiveUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `@spawnat` and `remotecall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = @spawnat :any varinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @spawnat :any calls nextproc to determine the process\n",
    "Distributed.nextproc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine spawn and fetch with `Distributed.@fetch`, `Distributed.@fetchfrom` or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotecall_fetch(varinfo, Distributed.nextproc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caution Magic: (implicitly) passing data between processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = @spawnat 2 begin\n",
    "    sum(A)\n",
    "end\n",
    "fetch(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.@fetchfrom 2 varinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no global definition with extra remotecall args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = rand(10,10)\n",
    "\n",
    "remotecall_fetch(B -> sum(B), 2, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.@fetchfrom 2 varinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "magic actually also works within `remotecall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotecall_fetch(()->sum(B), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.@fetchfrom 2 varinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to use the magical data transfer, you can use `let` to prevent global assignments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = rand(10,10)\n",
    "let C=C\n",
    "    remotecall_fetch(()->sum(C), 2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.@fetchfrom 2 varinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.clear!(:A)\n",
    "Distributed.@fetchfrom 2 varinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### your space 🤓\n",
    "\n",
    "👉 Check how much better `remotecall_fetch` is compared to `fetch(remotecall(...))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space\n",
    "\n",
    "using BenchmarkTools\n",
    "@btime 1 + 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RemoteChannel`\n",
    "\n",
    "Here a really nice example of complex communication between different machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const jobs = RemoteChannel(()->Channel{Int}(32));\n",
    "const results = RemoteChannel(()->Channel{Tuple}(32));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function do_work(jobs, results) # define work function everywhere\n",
    "    while true\n",
    "        job_id = take!(jobs)\n",
    "        exec_time = rand()\n",
    "        sleep(exec_time) # simulates elapsed time doing actual work\n",
    "        put!(results, (job_id, exec_time, myid()))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_jobs(n)\n",
    "    for i in 1:n\n",
    "        put!(jobs, i)\n",
    "    end\n",
    "end;\n",
    "\n",
    "n = 12;\n",
    "errormonitor(@async make_jobs(n)); # feed the jobs channel with \"n\" jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in workers() # start tasks on the workers to process requests in parallel\n",
    "    remote_do(do_work, p, jobs, results)\n",
    "end\n",
    "\n",
    "@elapsed while n > 0 # print out results\n",
    "    job_id, exec_time, where = take!(results)\n",
    "    println(\"$job_id finished in $(round(exec_time; digits=2)) seconds on worker $where\")\n",
    "    global n = n - 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nheads = @distributed (+) for i = 1:20000\n",
    "    Int(rand(Bool))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "M = [rand(5,5) for i = 1:4]\n",
    "pmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other packages\n",
    "- stdlib [`SharedArrays`](https://docs.julialang.org/en/v1/stdlib/SharedArrays/) to share one large array on multiple processes **on the same machine**\n",
    "- package [`DistributedArrays`](https://juliaparallel.org/DistributedArrays.jl/stable/) distribute Arrays over multiple machines \n",
    "- package [`DTables`](https://github.com/JuliaParallel/DTables.jl) distribute Tables (e.g. Dataframes) over multiple machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wouldn't it be great to just have a distributed `@spawn`?\n",
    "\n",
    "Welcome [`Dagger.jl`](https://github.com/JuliaParallel/Dagger.jl)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Dagger.@spawn 1+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Dagger.@spawn rand(a, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Dagger.@spawn sum(b)\n",
    "fetch(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary (taken from julia documentation)\n",
    "\n",
    "Julia supports these four categories of concurrent and parallel programming:\n",
    "\n",
    "1. **Asynchronous \"tasks\", or coroutines**:\n",
    "\n",
    "    Julia Tasks allow suspending and resuming computations\n",
    "    for I/O, event handling, producer-consumer processes, and similar patterns.\n",
    "    Tasks can synchronize through operations like [`wait`](https://docs.julialang.org/en/v1/base/parallel/#Base.wait) and [`fetch`](https://docs.julialang.org/en/v1/base/parallel/#Base.fetch-Tuple{Task}), and\n",
    "    communicate via [`Channel`](https://docs.julialang.org/en/v1/base/parallel/#Base.Channel)s. While strictly not parallel computing by themselves,\n",
    "    Julia lets you schedule [`Task`](https://docs.julialang.org/en/v1/base/parallel/#Core.Task)s on several threads.\n",
    "\n",
    "2. **Multi-threading**:\n",
    "\n",
    "    Julia's [multi-threading](https://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading) provides the ability to schedule Tasks\n",
    "    simultaneously on more than one thread or CPU core, sharing memory. This is usually the easiest way\n",
    "    to get parallelism on one's PC or on a single large multi-core server. Julia's multi-threading\n",
    "    is composable. When one multi-threaded function calls another multi-threaded function, Julia\n",
    "    will schedule all the threads globally on available resources, without oversubscribing.\n",
    "\n",
    "3. **Distributed computing**:\n",
    "\n",
    "    Distributed computing runs multiple Julia processes with separate memory spaces. These can be on the same\n",
    "    computer or multiple computers. The [`Distributed`](https://docs.julialang.org/en/v1/stdlib/Distributed/#man-distributed) standard library provides the capability for remote execution\n",
    "    of a Julia function. With this basic building block, it is possible to build many different kinds of\n",
    "    distributed computing abstractions. Packages like [`DistributedArrays.jl`](https://github.com/JuliaParallel/DistributedArrays.jl)\n",
    "    are an example of such an abstraction. On the other hand, packages like [`MPI.jl`](https://github.com/JuliaParallel/MPI.jl) and\n",
    "    [`Elemental.jl`](https://github.com/JuliaParallel/Elemental.jl) provide access to the existing MPI ecosystem of libraries.\n",
    "\n",
    "4. **GPU computing**:\n",
    "\n",
    "    The Julia GPU compiler provides the ability to run Julia code natively on GPUs. There\n",
    "    is a rich ecosystem of Julia packages that target GPUs. The [JuliaGPU.org](https://juliagpu.org)\n",
    "    website provides a list of capabilities, supported GPUs, related packages and documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for your participation\n",
    "\n",
    "for questions or suggestions please contact me at stephan.sahm@jolin.io\n",
    "\n",
    "\n",
    "Sponsored by [Jolin.io](https://www.jolin.io)\n",
    "\n",
    "<a href=\"https://www.jolin.io\" target=\"_blank\" rel=\"noreferrer noopener\">\n",
    "<img src=\"https://www.jolin.io/assets/Jolin/Jolin-Banner-Website-v1.1-darkmode.webp\">\n",
    "</a>\n",
    "\n",
    "Jolin.io is an IT-consultancy focussing on Julia\n",
    "\n",
    "We are there to help you, if you want to\n",
    "- try out Julia at your company, or\n",
    "- transition Matlab, Fortran, R, Python, etc. to Julia\n",
    "- or speed up your existing Julia code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia",
   "language": "julia",
   "name": "julia"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "520e995520d0f28b9f1e7cacfd9ba1493aa60b57e5f0cc1543205df7dd9220a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
